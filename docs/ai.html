
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Odoo Configuration and Customization Expert">
      
      
        <meta name="author" content="Paresh Wagh">
      
      
        <link rel="canonical" href="https://pawa2007.github.io/ai.html">
      
      
        <link rel="prev" href="javascript.html">
      
      
        <link rel="next" href="ESR.html">
      
      
      <link rel="icon" href="images/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Artificial Intelligence - Paresh Wagh</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
        <script src="https://unpkg.com/iframe-worker/shim"></script>
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="assets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#artificial-intelligence-ai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Paresh Wagh" class="md-header__button md-logo" aria-label="Paresh Wagh" data-md-component="logo">
      
  <img src="images/photo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Paresh Wagh
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Artificial Intelligence
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="deep-purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="deep-purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/pawa2007/pawa2007.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pawa2007/pawa2007.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="index.html" class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="odoo.html" class="md-tabs__link">
          
  
  
  Continuous Learning

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="about.html" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Paresh Wagh" class="md-nav__button md-logo" aria-label="Paresh Wagh" data-md-component="logo">
      
  <img src="images/photo.png" alt="logo">

    </a>
    Paresh Wagh
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pawa2007/pawa2007.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    pawa2007/pawa2007.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Continuous Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Continuous Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="odoo.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Odoo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="python.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python & Data Science
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="javascript.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    JavaScript & TypeScript
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Artificial Intelligence
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="ai.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Artificial Intelligence
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#responsible-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Responsible AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-roadmap" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Roadmap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-guides" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Guides
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cheatsheets" class="md-nav__link">
    <span class="md-ellipsis">
      Cheatsheets
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Patterns
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#online-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Online Courses
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compilations" class="md-nav__link">
    <span class="md-ellipsis">
      Compilations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tools" class="md-nav__link">
    <span class="md-ellipsis">
      Tools
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development-frameworks" class="md-nav__link">
    <span class="md-ellipsis">
      Development Frameworks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#communities" class="md-nav__link">
    <span class="md-ellipsis">
      Communities
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#research" class="md-nav__link">
    <span class="md-ellipsis">
      Research
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frontier-models-as-of-august-28-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Frontier Models (As of August 28, 2024)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-trained-models" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-trained Models
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ESR.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ESR
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="books.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Books
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="about.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#responsible-ai" class="md-nav__link">
    <span class="md-ellipsis">
      Responsible AI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-roadmap" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Roadmap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-guides" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Guides
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cheatsheets" class="md-nav__link">
    <span class="md-ellipsis">
      Cheatsheets
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Patterns
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#online-courses" class="md-nav__link">
    <span class="md-ellipsis">
      Online Courses
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compilations" class="md-nav__link">
    <span class="md-ellipsis">
      Compilations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tools" class="md-nav__link">
    <span class="md-ellipsis">
      Tools
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development-frameworks" class="md-nav__link">
    <span class="md-ellipsis">
      Development Frameworks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#communities" class="md-nav__link">
    <span class="md-ellipsis">
      Communities
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#research" class="md-nav__link">
    <span class="md-ellipsis">
      Research
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frontier-models-as-of-august-28-2024" class="md-nav__link">
    <span class="md-ellipsis">
      Frontier Models (As of August 28, 2024)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-trained-models" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-trained Models
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="artificial-intelligence-ai">Artificial Intelligence (AI)</h1>
<p>Notes along the AI journey</p>
<h2 id="responsible-ai">Responsible AI</h2>
<ul>
<li><a href="https://airc.nist.gov/home">NIST Trustworthy &amp; Responsible AI Resource Center</a></li>
<li><a href="https://llama.meta.com/responsible-use-guide/">Meta Responsible Use Guide</a></li>
<li><a href="https://www.ibm.com/topics/responsible-ai">IBM</a></li>
<li><a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2">Microsoft</a></li>
<li><a href="https://openai.com/safety/">OpenAI</a></li>
<li><a href="https://www.anthropic.com/news/core-views-on-ai-safety">Anthropic</a></li>
<li><a href="https://ai.google/responsibility/responsible-ai-practices/">Google</a></li>
<li><a href="https://sites.research.google/datacardsplaybook/">Google Data Cards Playbook</a></li>
</ul>
<h2 id="prompt-engineering-roadmap">Prompt Engineering Roadmap</h2>
<ul>
<li><a href="https://roadmap.sh/prompt-engineering">Prompt Engineering Roadmap</a></li>
</ul>
<h2 id="prompt-engineering-guides">Prompt Engineering Guides</h2>
<ul>
<li><a href="https://www.promptingguide.ai/">DAIR.AI</a></li>
<li><a href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI</a></li>
<li><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview">Anthropic <em>(Claude)</em></a></li>
<li><a href="https://learnprompting.org/docs/introduction">Learn Prompting</a></li>
<li><a href="https://llama.meta.com/docs/how-to-guides/prompting/">Meta <em>(Llama)</em></a></li>
<li><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design">Google Vertex AI</a></li>
<li><a href="https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot">GitHub Copilot</a></li>
<li><a href="https://github.com/brexhq/prompt-engineering">Brex</a></li>
<li><a href="https://docs.cohere.com/docs/crafting-effective-prompts">Cohere Docs</a></li>
<li><a href="https://cohere.com/blog/how-to-train-your-pet-llm-prompt-engineering">How to train your pet LLM <em>(Cohere)</em></a></li>
<li><a href="https://cheatsheet.md/claude/claude-prompt-engineering">Claude Prompt Engineering Guide <em>(cheatsheet.md)</em></a></li>
<li><a href="https://microsoft.github.io/prompt-engineering/">How to get Codex to produce the code you want! <em>(Microsoft)</em></a></li>
<li><a href="https://docs.ai21.com/docs/prompt-engineering">AI21 <em>(Jamba)</em></a></li>
<li><a href="https://docs.mistral.ai/guides/prompting_capabilities/">Mistral</a></li>
<li><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html">AWS</a></li>
</ul>
<h2 id="best-practices">Best Practices</h2>
<ul>
<li><a href="https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api">Best practices for prompt engineering with the OpenAI API</a></li>
</ul>
<h2 id="cheatsheets">Cheatsheets</h2>
<ul>
<li><a href="https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-mxkcf/">The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 1 <em>(Maximilian Vogel)</em></a></li>
<li><a href="https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-ukysf">The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 2 <em>(Maximilian Vogel)</em></a></li>
<li><a href="https://aituts.com/midjourney-cheatsheet/">Midjourney Commands Cheatsheet <em>(aituts.com)</em></a></li>
<li><a href="https://lifearchitect.ai/chatgpt-prompt-book/">ChatGPT Prompt Book <em>(Dr. Alan D. Thompson)</em></a></li>
<li><a href="https://github.com/f/awesome-chatgpt-prompts">Awesome ChatGPT Prompts</a></li>
<li><a href="https://github.com/travistangvh/ChatGPT-Data-Science-Prompts">ChatGPT Prompts for Data Science!</a></li>
<li><a href="https://www.superside.com/blog/chatgpt-prompts">How to Write the Best ChatGPT Prompts (Cheat Sheet for 2024)</a></li>
<li><a href="https://openart.ai/promptbook">Stable Diffusion Prompt Book</a></li>
<li><a href="https://dallery.gallery/the-dalle-2-prompt-book/">DALL-E 2 Prompt Book</a></li>
<li><a href="https://usefulai.com/cheat-sheets/chatgpt">7 Best ChatGPT Cheat Sheets in 2024</a></li>
<li><a href="https://www.aifire.co/p/top-ai-cheatsheets-2024">AIFire Cheatsheets</a></li>
</ul>
<h2 id="prompt-engineering-patterns">Prompt Engineering Patterns</h2>
<ul>
<li><a href="https://github.com/corralm/awesome-prompting">Awesome Prompting</a></li>
</ul>
<h2 id="online-courses">Online Courses</h2>
<ul>
<li><a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/">ChatGPT Prompt Engineering for Developers</a></li>
<li><a href="https://www.deeplearning.ai/short-courses/pair-programming-llm/">Pair Programming with a Large Language Model</a></li>
<li><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/">Prompt Engineering with Llama 2 &amp; 3</a></li>
<li><a href="https://github.com/microsoft/generative-ai-for-beginners">Generative AI for Beginners <em>(Microsoft)</em></a></li>
<li><a href="https://learningprompt.wiki/">Learning Prompt <em>(Jimmy Wong)</em></a></li>
<li><a href="https://natnew.github.io/Awesome-Prompt-Engineering/">Awesome Prompt Engineering <em>(Natasha Newbold)</em></a></li>
</ul>
<h2 id="compilations">Compilations</h2>
<ul>
<li><a href="https://github.com/snwfdhmp/awesome-gpt-prompt-engineering">Awesome GPT Prompt Engineering</a></li>
<li><a href="https://github.com/promptslab/Awesome-Prompt-Engineering">Awesome Prompt Engineering</a></li>
<li><a href="https://github.com/ai-boost/awesome-prompts">Awesome Prompts</a></li>
<li><a href="https://www.aifire.co/c/ai-learning-resources">AIFire AI Learning Resources</a></li>
</ul>
<h2 id="tools">Tools</h2>
<ul>
<li><a href="https://huggingface.co/spaces/merve/ChatGPT-prompt-generator">ChatGPT Prompt Generator</a></li>
<li><a href="https://huggingface.co/datasets/fka/awesome-chatgpt-prompts/viewer/default/train">Training Dataset used for the ChatGPT Prompt Generator</a></li>
</ul>
<h2 id="development-frameworks">Development Frameworks</h2>
<ul>
<li><a href="https://www.langchain.com/">LangChain</a></li>
</ul>
<h2 id="communities">Communities</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co">Hugging Face</a></td>
<td>One of the largest AI model and dataset repositories. Offers pre-trained models for various tasks like text generation, translation, image classification. Allows community contributions. Provides hosting solutions like Inference Endpoints.</td>
</tr>
<tr>
<td><a href="https://www.kaggle.com">Kaggle</a></td>
<td>World's largest data science community with tools and resources for machine learning and data science projects. Users can participate in coding competitions, access datasets, notebooks, and pre-trained models. Provides a platform for hosting and sharing models, datasets, and projects.</td>
</tr>
</tbody>
</table>
<h2 id="research">Research</h2>
<ul>
<li><a href="https://arxiv.org">arXiv</a></li>
<li><a href="https://www.semanticscholar.org/">Semantic Scholar <em>(Search Engine)</em></a></li>
<li><a href="https://aclanthology.org/">Association for Computational Linguistics</a></li>
</ul>
<h2 id="frontier-models-as-of-august-28-2024">Frontier Models (As of August 28, 2024)</h2>
<p>Source: <a href="https://www.perplexity.ai">Perplexity.ai</a></p>
<!-- list frontier ai models released during the last year. sort the results by model release date in descending order. display the results in a tabular format with columns for model name as a hyperlink to website, capabilities, release date. release date format should in Month YYYY, for example, January 2025. generate the table only after all the data has been sorted. -->

<table>
<thead>
<tr>
<th>Model Name</th>
<th>Capabilities</th>
<th>Release Date</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://openai.com/research/gpt-5">GPT-5</a></td>
<td>Next-generation language model</td>
<td>Expected late 2024</td>
</tr>
<tr>
<td><a href="https://ai.googleblog.com/2024/01/gemini-ultra.html">Gemini Ultra</a></td>
<td>Advanced language and multimodal capabilities</td>
<td>January 2024</td>
</tr>
<tr>
<td><a href="https://www.anthropic.com/claude">Claude 3</a></td>
<td>Enhanced conversational AI and reasoning</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://mistral.ai/">Mistral 7B</a></td>
<td>Efficient language generation</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://ai.meta.com/llama/">Llama 2 70B</a></td>
<td>Large language model for various tasks</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://www.huggingface.co/tiiuae/falcon-180b">Falcon 180B</a></td>
<td>High-performance language model</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://ai.googleblog.com/2023/12/gemini.html">Gemini</a></td>
<td>Multimodal capabilities for AI tasks</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://mistral.ai/mixtral">Mixtral</a></td>
<td>Multi-task language model</td>
<td>December 2023</td>
</tr>
<tr>
<td><a href="https://open-assistant.io/">OpenAssistant</a></td>
<td>Open-source conversational agent</td>
<td>October 2023</td>
</tr>
<tr>
<td><a href="https://openai.com/dall-e-3">DALL-E 3</a></td>
<td>Enhanced image generation capabilities</td>
<td>September 2023</td>
</tr>
<tr>
<td><a href="https://stability.ai/blog/stable-diffusion-xl">Stable Diffusion XL</a></td>
<td>Enhanced image generation model</td>
<td>August 2023</td>
</tr>
<tr>
<td><a href="https://llava.ai/">LLava</a></td>
<td>Language and vision integration</td>
<td>July 2023</td>
</tr>
<tr>
<td><a href="https://www.anthropic.com/claude">Claude 2</a></td>
<td>Improved conversational AI</td>
<td>July 2023</td>
</tr>
<tr>
<td><a href="https://ai.meta.com/llama/">LLaMA 2</a></td>
<td>Open-source language model</td>
<td>July 2023</td>
</tr>
<tr>
<td><a href="https://docs.ray.io/en/latest/serve/index.html">Ray Serve</a></td>
<td>Scalable model serving</td>
<td>July 2023</td>
</tr>
<tr>
<td><a href="https://vllm.readthedocs.io/en/latest/">vLLM</a></td>
<td>Efficient language model serving</td>
<td>August 2023</td>
</tr>
<tr>
<td><a href="https://www.huggingface.co/models?search=vision+assistant">Vision Assistant</a></td>
<td>Multimodal vision processing</td>
<td>June 2023</td>
</tr>
<tr>
<td><a href="https://ai.googleblog.com/2023/04/introducing-palm-2.html">PaLM 2</a></td>
<td>Multimodal language processing</td>
<td>April 2023</td>
</tr>
<tr>
<td><a href="https://bard.google.com">Bard</a></td>
<td>Conversational AI with web integration</td>
<td>March 2023</td>
</tr>
<tr>
<td><a href="https://www.adobe.com/sensei/generative-ai/firefly.html">Firefly</a></td>
<td>Generative design and image editing</td>
<td>March 2023</td>
</tr>
<tr>
<td><a href="https://www.anthropic.com/claude">Anthropic's Claude</a></td>
<td>Safety-oriented conversational AI</td>
<td>March 2023</td>
</tr>
<tr>
<td><a href="https://openai.com/research/gpt-3-5-turbo">GPT-3.5 Turbo</a></td>
<td>Faster and cheaper version of GPT-3.5</td>
<td>March 2023</td>
</tr>
<tr>
<td><a href="https://openai.com/research/gpt-4">GPT-4</a></td>
<td>State-of-the-art language understanding</td>
<td>March 2023</td>
</tr>
<tr>
<td><a href="https://openai.com/chatgpt">ChatGPT-4.5</a></td>
<td>Improved conversational capabilities</td>
<td>February 2023</td>
</tr>
<tr>
<td><a href="https://langchain.com/">Langchain</a></td>
<td>Framework for building LLM applications</td>
<td>February 2023</td>
</tr>
<tr>
<td><a href="https://gptindex.readthedocs.io/en/latest/">LlamaIndex</a></td>
<td>Data indexing for LLMs</td>
<td>January 2023</td>
</tr>
<tr>
<td><a href="https://www.eleuther.ai/projects/gpt-neox/">EleutherAI's GPT-NeoX</a></td>
<td>Open-source large language model</td>
<td>January 2023</td>
</tr>
<tr>
<td><a href="https://huggingface.co/docs/transformers/main/en/index">Text Generation Inference</a></td>
<td>Efficient text generation</td>
<td>April 2023</td>
</tr>
<tr>
<td><a href="https://cohere.ai/">Cohere Command R</a></td>
<td>Language model for command generation</td>
<td>April 2023</td>
</tr>
<tr>
<td><a href="https://deepmind.com/research/publications/gato">DeepMind's Gato</a></td>
<td>Generalist agent for various tasks</td>
<td>May 2022</td>
</tr>
<tr>
<td><a href="https://stability.ai/blog/stable-diffusion-v2">Stable Diffusion 2.0</a></td>
<td>Advanced image synthesis</td>
<td>November 2022</td>
</tr>
<tr>
<td><a href="https://openai.com/chatgpt">ChatGPT-3.5</a></td>
<td>Conversational AI with improved context</td>
<td>November 2022</td>
</tr>
<tr>
<td><a href="https://www.ai21.com/jurassic-2">Jurassic-2</a></td>
<td>Advanced natural language processing</td>
<td>November 2022</td>
</tr>
<tr>
<td><a href="https://deepai.org/machine-learning-model/text2img">DeepAI's Text to Image</a></td>
<td>Text-to-image generation</td>
<td>November 2022</td>
</tr>
<tr>
<td><a href="https://openai.com/dall-e-2">DALL-E 2</a></td>
<td>Image generation from text prompts</td>
<td>September 2022</td>
</tr>
<tr>
<td><a href="https://openai.com/research/whisper">OpenAI's Whisper</a></td>
<td>Speech recognition and transcription</td>
<td>September 2022</td>
</tr>
<tr>
<td><a href="https://openai.com/research/codex">OpenAI Codex</a></td>
<td>Code generation and understanding</td>
<td>August 2022</td>
</tr>
</tbody>
</table>
<h2 id="pre-trained-models">Pre-trained Models</h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>Full Name</th>
<th>Description</th>
<th>Company</th>
<th>Date</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/google-research/bert">BERT</a></td>
<td>Bidirectional Encoder Representations from Transformers</td>
<td>Designed for understanding the context of words in search queries.</td>
<td>Google</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://openai.com/blog/gpt-3/">GPT-3</a></td>
<td>Generative Pre-trained Transformer 3</td>
<td>A state-of-the-art language model capable of generating human-like text based on prompts.</td>
<td>OpenAI</td>
<td>June 2020</td>
</tr>
<tr>
<td><a href="https://github.com/KaimingHe/deep-residual-networks">ResNet</a></td>
<td>Residual Network</td>
<td>A deep residual learning framework that helps in training very deep neural networks.</td>
<td>Microsoft</td>
<td>January 2020</td>
</tr>
<tr>
<td><a href="https://www.robots.ox.ac.uk/~vgg/research/very_deep/">VGG</a></td>
<td>Visual Geometry Group</td>
<td>A convolutional neural network architecture known for its simplicity and depth, used primarily for image classification.</td>
<td>University of Oxford</td>
<td>September 2015</td>
</tr>
<tr>
<td><a href="https://pjreddie.com/darknet/yolo/">YOLO</a></td>
<td>You Only Look Once</td>
<td>A real-time object detection system that detects objects in images and videos.</td>
<td>Joseph Redmon</td>
<td>April 2020</td>
</tr>
<tr>
<td><a href="https://github.com/weiliu89/caffe/tree/ssd">SSD</a></td>
<td>Single Shot MultiBox Detector</td>
<td>A single-shot detector that detects objects in images using a single deep neural network.</td>
<td>Wei Liu</td>
<td>March 2016</td>
</tr>
<tr>
<td><a href="https://github.com/rbgirshick/py-faster-rcnn">Faster R-CNN</a></td>
<td>Faster Region-based Convolutional Neural Network</td>
<td>An object detection model that combines region proposal networks with fast R-CNN.</td>
<td>Microsoft</td>
<td>April 2017</td>
</tr>
<tr>
<td><a href="https://github.com/matterport/Mask_RCNN">Mask R-CNN</a></td>
<td>Mask Region-based Convolutional Neural Network</td>
<td>An extension of Faster R-CNN that adds a branch for predicting segmentation masks on each Region of Interest (RoI).</td>
<td>Facebook AI Research</td>
<td>November 2018</td>
</tr>
<tr>
<td><a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">U-Net</a></td>
<td>U-Net Convolutional Network</td>
<td>A convolutional network architecture for biomedical image segmentation.</td>
<td>University of Freiburg</td>
<td>January 2018</td>
</tr>
<tr>
<td><a href="https://github.com/alexgkendall/SegNet-Tutorial">SegNet</a></td>
<td>Segmentation Network</td>
<td>A deep convolutional encoder-decoder architecture for semantic segmentation.</td>
<td>University of Cambridge</td>
<td>August 2017</td>
</tr>
<tr>
<td><a href="https://github.com/hszhao/PSPNet">PSPNet</a></td>
<td>Pyramid Scene Parsing Network</td>
<td>A semantic segmentation model that captures global context information through a pyramid pooling module.</td>
<td>University of Science and Technology of China</td>
<td>March 2018</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/models/tree/master/research/deeplab">DeepLabV3</a></td>
<td>DeepLab Version 3</td>
<td>A semantic segmentation model that uses atrous convolution to capture multi-scale context.</td>
<td>Google</td>
<td>October 2019</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/models/tree/master/research/deeplab">DeepLabV3+</a></td>
<td>DeepLab Version 3 Plus</td>
<td>An improved version of DeepLabV3 that includes an encoder-decoder structure for better segmentation.</td>
<td>Google</td>
<td>October 2019</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet">EfficientNet</a></td>
<td>Efficient Neural Network</td>
<td>A family of convolutional neural networks that scale efficiently with model size and input resolution.</td>
<td>Google</td>
<td>September 2020</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v2.md">MobileNet</a></td>
<td>Mobile Neural Network</td>
<td>A lightweight model designed for mobile and edge devices, optimized for speed and efficiency.</td>
<td>Google</td>
<td>June 2019</td>
</tr>
<tr>
<td><a href="https://github.com/megvii-model/ShuffleNet">ShuffleNet</a></td>
<td>Shuffle Neural Network</td>
<td>A lightweight convolutional neural network architecture designed for mobile devices.</td>
<td>Megvii Technology</td>
<td>January 2018</td>
</tr>
<tr>
<td><a href="https://github.com/forresti/SqueezeNet">SqueezeNet</a></td>
<td>Squeeze Neural Network</td>
<td>A small, efficient convolutional neural network that achieves AlexNet-level accuracy with fewer parameters.</td>
<td>DeepScale</td>
<td>March 2020</td>
</tr>
<tr>
<td><a href="https://github.com/goodfeli/adversarial">GAN</a></td>
<td>Generative Adversarial Network</td>
<td>A framework for training generative models using adversarial training.</td>
<td>Ian Goodfellow et al.</td>
<td>November 2014</td>
</tr>
<tr>
<td><a href="https://github.com/dpkingma/vae">VAE</a></td>
<td>Variational Autoencoder</td>
<td>A generative model that learns to encode data into a latent space and decode it back.</td>
<td>Diederik P Kingma et al.</td>
<td>December 2013</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/examples/tree/master/dcgan">DCGAN</a></td>
<td>Deep Convolutional GAN</td>
<td>A type of GAN that uses deep convolutional networks for generating images.</td>
<td>Facebook AI Research</td>
<td>March 2016</td>
</tr>
<tr>
<td><a href="https://github.com/martinarjovsky/WassersteinGAN">WGAN</a></td>
<td>Wasserstein GAN</td>
<td>A variant of GAN that uses Wasserstein distance for training stability.</td>
<td>Martin Arjovsky et al.</td>
<td>June 2017</td>
</tr>
<tr>
<td><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py">LSTM</a></td>
<td>Long Short-Term Memory</td>
<td>A type of recurrent neural network that can learn long-term dependencies.</td>
<td>Google</td>
<td>June 2020</td>
</tr>
<tr>
<td><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py">GRU</a></td>
<td>Gated Recurrent Unit</td>
<td>A type of recurrent neural network that is simpler than LSTM and also captures long-term dependencies.</td>
<td>Google</td>
<td>June 2020</td>
</tr>
<tr>
<td><a href="https://github.com/google/seq2seq">Seq2Seq</a></td>
<td>Sequence-to-Sequence</td>
<td>A model used for sequence-to-sequence tasks, such as translation.</td>
<td>Google</td>
<td>December 2016</td>
</tr>
<tr>
<td><a href="https://github.com/tensorflow/models/tree/master/official/transformer">Transformer</a></td>
<td>Transformer Model</td>
<td>A model architecture that uses self-attention mechanisms for sequence processing.</td>
<td>Google</td>
<td>June 2017</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/fairseq/tree/master/examples/bart">BART</a></td>
<td>Bidirectional and Auto-Regressive Transformers</td>
<td>A model that combines bidirectional and autoregressive transformers for sequence generation.</td>
<td>Facebook AI Research</td>
<td>March 2020</td>
</tr>
<tr>
<td><a href="https://github.com/google-research/text-to-text-transfer-transformer">T5</a></td>
<td>Text-to-Text Transfer Transformer</td>
<td>A text-to-text transformer that can handle various NLP tasks by converting them into a text generation format.</td>
<td>Google</td>
<td>July 2021</td>
</tr>
<tr>
<td><a href="https://github.com/zihangdai/xlnet">XLNet</a></td>
<td>Generalized Autoregressive Pretraining</td>
<td>A generalized autoregressive pretraining model that captures bidirectional context.</td>
<td>Google</td>
<td>June 2019</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta">RoBERTa</a></td>
<td>A Robustly Optimized BERT Pretraining Approach</td>
<td>An optimized version of BERT that improves performance on various NLP tasks.</td>
<td>Facebook AI Research</td>
<td>July 2021</td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/master/examples/distillation">DistilBERT</a></td>
<td>Distilled BERT</td>
<td>A distilled version of BERT that is smaller and faster while retaining most of its performance.</td>
<td>Hugging Face</td>
<td>October 2020</td>
</tr>
<tr>
<td><a href="https://github.com/google-research/ALBERT">ALBERT</a></td>
<td>A Lite BERT</td>
<td>A lite version of BERT that reduces model size with parameter sharing and factorized embeddings.</td>
<td>Google</td>
<td>September 2020</td>
</tr>
<tr>
<td><a href="https://github.com/facebookresearch/XLM">XLM</a></td>
<td>Cross-lingual Language Model</td>
<td>A cross-lingual language model that learns representations for multiple languages.</td>
<td>Facebook AI Research</td>
<td>July 2021</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/fairseq/tree/master/examples/xlmr">XLM-RoBERTa</a></td>
<td>Cross-lingual RoBERTa</td>
<td>A multilingual version of RoBERTa that performs well on various cross-lingual tasks.</td>
<td>Facebook AI Research</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://github.com/getalp/Flaubert">FlauBERT</a></td>
<td>French Language Model</td>
<td>A French language model that is pre-trained on a large corpus of French text.</td>
<td>GETALP</td>
<td>December 2020</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/fairseq/tree/master/examples/mbart">mBART</a></td>
<td>Multilingual BART</td>
<td>A multilingual sequence-to-sequence model that can perform various NLP tasks across languages.</td>
<td>Facebook AI Research</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://github.com/google-research/electra">ELECTRA</a></td>
<td>Efficiently Learning an Encoder that Classifies Token Replacements Accurately</td>
<td>A model that trains discriminators to distinguish real from fake tokens, improving efficiency.</td>
<td>Google</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://github.com/microsoft/DeBERTa">DeBERTa</a></td>
<td>Decoding-enhanced BERT with Disentangled Attention</td>
<td>A model that enhances BERT with disentangled attention and an improved mask decoder.</td>
<td>Microsoft</td>
<td>February 2021</td>
</tr>
<tr>
<td><a href="https://github.com/google-research/realm">REALM</a></td>
<td>Retrieval-Augmented Language Model</td>
<td>A model that integrates retrieval into language modeling for enhanced understanding.</td>
<td>Google</td>
<td>October 2020</td>
</tr>
<tr>
<td><a href="https://github.com/salesforce/ctrl">CTRL</a></td>
<td>Conditional Transformer Language Model</td>
<td>A conditional transformer language model that can generate text based on control codes.</td>
<td>Salesforce</td>
<td>September 2019</td>
</tr>
<tr>
<td><a href="https://github.com/openai/gpt-2">GPT-2</a></td>
<td>Generative Pre-trained Transformer 2</td>
<td>A predecessor to GPT-3, known for generating coherent and contextually relevant text.</td>
<td>OpenAI</td>
<td>November 2019</td>
</tr>
<tr>
<td><a href="https://github.com/NVIDIA/Megatron-LM">Megatron-LM</a></td>
<td>Megatron Language Model</td>
<td>A large language model designed for efficient training on multiple GPUs.</td>
<td>Nvidia</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://openai.com/blog/dall-e/">DALL-E</a></td>
<td>DALL-E: Creating Images from Text</td>
<td>A model that generates images from textual descriptions, showcasing creativity and understanding.</td>
<td>OpenAI</td>
<td>January 2021</td>
</tr>
<tr>
<td><a href="https://openai.com/research/clip/">CLIP</a></td>
<td>Contrastive Language-Image Pre-training</td>
<td>A model that connects images and text, allowing for zero-shot classification of images based on text prompts.</td>
<td>OpenAI</td>
<td>January 2021</td>
</tr>
<tr>
<td><a href="https://github.com/NVlabs/stylegan">StyleGAN</a></td>
<td>Style Generative Adversarial Network</td>
<td>A generative adversarial network that creates high-quality images with controllable styles.</td>
<td>Nvidia</td>
<td>February 2021</td>
</tr>
<tr>
<td><a href="https://github.com/ajbrock/BigGAN-PyTorch">BigGAN</a></td>
<td>Large Scale GAN</td>
<td>A large-scale GAN that generates high-fidelity images with improved diversity.</td>
<td>Google</td>
<td>January 2021</td>
</tr>
<tr>
<td><a href="https://github.com/junyanz/CycleGAN">CycleGAN</a></td>
<td>Cycle-Consistent Adversarial Networks</td>
<td>A model that translates images from one domain to another without paired examples.</td>
<td>UC Berkeley</td>
<td>November 2020</td>
</tr>
<tr>
<td><a href="https://github.com/yunjey/stargan">StarGAN</a></td>
<td>Star Generative Adversarial Network</td>
<td>A unified model for multi-domain image-to-image translation.</td>
<td>Yunjey Choi et al.</td>
<td>September 2018</td>
</tr>
<tr>
<td><a href="https://github.com/phillipi/pix2pix">pix2pix</a></td>
<td>Image-to-Image Translation with Conditional Adversarial Networks</td>
<td>A conditional GAN for image-to-image translation tasks.</td>
<td>Phillip Isola et al.</td>
<td>January 2017</td>
</tr>
<tr>
<td><a href="https://github.com/mozilla/DeepSpeech">DeepSpeech</a></td>
<td>Deep Speech Recognition</td>
<td>An automatic speech recognition system based on deep learning.</td>
<td>Mozilla</td>
<td>March 2021</td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/fairseq/tree/master/examples/wav2vec">Wav2Vec</a></td>
<td>Wav2Vec: Unsupervised Pre-training for Speech Recognition</td>
<td>A self-supervised model for learning representations from raw audio data.</td>
<td>Facebook AI Research</td>
<td>June 2021</td>
</tr>
<tr>
<td><a href="https://github.com/facebookresearch/hubert">HuBERT</a></td>
<td>Hidden Unit BERT</td>
<td>A self-supervised learning model for speech representation learning.</td>
<td>Facebook AI Research</td>
<td>April 2021</td>
</tr>
<tr>
<td><a href="https://openai.com/research/whisper">Whisper</a></td>
<td>Whisper: Automatic Speech Recognition</td>
<td>A model for automatic speech recognition and transcription.</td>
<td>OpenAI</td>
<td>December 2022</td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Paresh Wagh
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/pawa2007" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:pawa2007@outlook.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "search.highlight", "search.share", "content.code.copy", "content.code.annotate"], "search": "assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.50899def.min.js"></script>
      
    
  </body>
</html>