# Artificial Intelligence (AI)
Notes along the AI journey

## Prompt Engineering Roadmap
* [Prompt Engineering Roadmap](https://roadmap.sh/prompt-engineering)

## Prompt Engineering Guides
* [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)
* [DAIR.AI](https://www.promptingguide.ai/)
* [Learn Prompting](https://learnprompting.org/docs/introduction)
* [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)
* [GitHub Copilot](https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot)
* [Brex](https://github.com/brexhq/prompt-engineering)
* [Cohere Docs](https://docs.cohere.com/docs/crafting-effective-prompts)
* [Claude Prompt Engineering Guide](https://cheatsheet.md/claude/claude-prompt-engineering)
* [How to get Codex to produce the code you want! _(Microsoft)_](https://microsoft.github.io/prompt-engineering/)

## Best Practices
* [Best practices for prompt engineering with the OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)

## Cheatsheets
* [The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 1 _(Maximilian Vogel)_](https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-mxkcf/)
* [The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 2 _(Maximilian Vogel)_](https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-ukysf)
* [Midjourney Commands Cheatsheet _(aituts.com)_](https://aituts.com/midjourney-cheatsheet/)
* [ChatGPT Prompt Book _(Dr. Alan D. Thompson)_](https://lifearchitect.ai/chatgpt-prompt-book/)
* [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)
* [ChatGPT Prompts for Data Science!](https://github.com/travistangvh/ChatGPT-Data-Science-Prompts)
* [How to Write the Best ChatGPT Prompts (Cheat Sheet for 2024)](https://www.superside.com/blog/chatgpt-prompts)
* [Stable Diffusion Prompt Book](https://openart.ai/promptbook)
* [DALL-E 2 Prompt Book](https://dallery.gallery/the-dalle-2-prompt-book/)
* [7 Best ChatGPT Cheat Sheets in 2024](https://usefulai.com/cheat-sheets/chatgpt)
* [AIFire Cheatsheets](https://www.aifire.co/p/top-ai-cheatsheets-2024)

## Prompt Engineering Patterns
* [Awesome Prompting](https://github.com/corralm/awesome-prompting)

## Online Courses
* [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
* [Pair Programming with a Large Language Model](https://www.deeplearning.ai/short-courses/pair-programming-llm/)
* [Prompt Engineering with Llama 2 & 3](https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/)
* [Generative AI for Beginners _(Microsoft)_](https://github.com/microsoft/generative-ai-for-beginners)
* [Learning Prompt _(Jimmy Wong)_](https://learningprompt.wiki/)
* [Awesome Prompt Engineering _(Natasha Newbold)_](https://natnew.github.io/Awesome-Prompt-Engineering/)

## Compilations
* [Awesome GPT Prompt Engineering](https://github.com/snwfdhmp/awesome-gpt-prompt-engineering)
* [Awesome Prompt Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)
* [Awesome Prompts](https://github.com/ai-boost/awesome-prompts)
* [AIFire AI Learning Resources](https://www.aifire.co/c/ai-learning-resources)

## Tools
* [ChatGPT Prompt Generator](https://huggingface.co/spaces/merve/ChatGPT-prompt-generator)
* [Training Dataset used for the ChatGPT Prompt Generator](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts/viewer/default/train)

## Communities

| Name | Description | URL |
|------|-------------|-----|
| Hugging Face     | One of the largest AI model and dataset repositories. Offers pre-trained models for various tasks like text generation, translation, image classification. Allows community contributions. Provides hosting solutions like Inference Endpoints. | [Hugging Face](https://huggingface.co) |
| Kaggle           | World's largest data science community with tools and resources for machine learning and data science projects. Users can participate in coding competitions, access datasets, notebooks, and pre-trained models. Provides a platform for hosting and sharing models, datasets, and projects. | [Kaggle](https://www.kaggle.com) |
| Together AI      | AI acceleration cloud that provides infrastructure for running, fine-tuning and training large language models. Offers serverless and dedicated instances for inference, fine-tuning with proprietary data, and training custom models. Powered by cutting-edge research for optimized performance. | [Together AI](https://www.together.ai) |
| TensorFlow Hub   | Library for reusable machine learning models. Provides a collection of pre-trained models ready to be used in applications with minimal code. Models cover image classification, text embedding, question answering and more. | [TensorFlow Hub](https://tfhub.dev) |
| PyTorch Hub      | Model repository for hosting pre-trained models. Allows users to load models directly from the repository and use them in their applications. Models cover computer vision, natural language processing, speech recognition and more. Makes it easy to leverage state-of-the-art models without having to train from scratch. | [PyTorch Hub](https://pytorch.org/hub) |

## Pre-trained Models

| Model | Description | Company | URL | Date |
|-------|-------------|---------|-------------|--------------|
| BERT | Bidirectional Encoder Representations from Transformers, designed for understanding the context of words in search queries. | Google | [Link](https://github.com/google-research/bert) | March 2021 |
| GPT-3 | A state-of-the-art language model capable of generating human-like text based on prompts. | OpenAI | [Link](https://openai.com/blog/gpt-3/) | June 2020 |
| ResNet | A deep residual learning framework that helps in training very deep neural networks. | Microsoft | [Link](https://github.com/KaimingHe/deep-residual-networks) | January 2020 |
| VGG | A convolutional neural network architecture known for its simplicity and depth, used primarily for image classification. | University of Oxford | [Link](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) | September 2015 |
| YOLO | A real-time object detection system that detects objects in images and videos. | Joseph Redmon | [Link](https://pjreddie.com/darknet/yolo/) | April 2020 |
| SSD | A single-shot detector that detects objects in images using a single deep neural network. | Wei Liu et al. | [Link](https://github.com/weiliu89/caffe/tree/ssd) | March 2016 |
| Faster R-CNN | An object detection model that combines region proposal networks with fast R-CNN. | Microsoft | [Link](https://github.com/rbgirshick/py-faster-rcnn) | April 2017 |
| Mask R-CNN | An extension of Faster R-CNN that adds a branch for predicting segmentation masks on each Region of Interest (RoI). | Facebook AI Research | [Link](https://github.com/matterport/Mask_RCNN) | November 2018 |
| U-Net | A convolutional network architecture for biomedical image segmentation. | University of Freiburg | [Link](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) | January 2018 |
| SegNet | A deep convolutional encoder-decoder architecture for semantic segmentation. | University of Cambridge | [Link](https://github.com/alexgkendall/SegNet-Tutorial) | August 2017 |
| PSPNet | A semantic segmentation model that captures global context information through a pyramid pooling module. | University of Science and Technology of China | [Link](https://github.com/hszhao/PSPNet) | March 2018 |
| DeepLabV3 | A semantic segmentation model that uses atrous convolution to capture multi-scale context. | Google | [Link](https://github.com/tensorflow/models/tree/master/research/deeplab) | October 2019 |
| DeepLabV3+ | An improved version of DeepLabV3 that includes an encoder-decoder structure for better segmentation. | Google | [Link](https://github.com/tensorflow/models/tree/master/research/deeplab) | October 2019 |
| EfficientNet | A family of convolutional neural networks that scale efficiently with model size and input resolution. | Google | [Link](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet) | September 2020 |
| MobileNet | A lightweight model designed for mobile and edge devices, optimized for speed and efficiency. | Google | [Link](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v2.md) | June 2019 |
| ShuffleNet | A lightweight convolutional neural network architecture designed for mobile devices. | Megvii Technology | [Link](https://github.com/megvii-model/ShuffleNet) | January 2018 |
| SqueezeNet | A small, efficient convolutional neural network that achieves AlexNet-level accuracy with fewer parameters. | DeepScale | [Link](https://github.com/forresti/SqueezeNet) | March 2020 |
| GAN | A framework for training generative models using adversarial training. | Ian Goodfellow et al. | [Link](https://github.com/goodfeli/adversarial) | November 2014 |
| VAE | A generative model that learns to encode data into a latent space and decode it back. | Diederik P Kingma et al. | [Link](https://github.com/dpkingma/vae) | December 2013 |
| DCGAN | A type of GAN that uses deep convolutional networks for generating images. | Facebook AI Research | [Link](https://github.com/pytorch/examples/tree/master/dcgan) | March 2016 |
| WGAN | A variant of GAN that uses Wasserstein distance for training stability. | Martin Arjovsky et al. | [Link](https://github.com/martinarjovsky/WassersteinGAN) | June 2017 |
| LSTM | A type of recurrent neural network that can learn long-term dependencies. | Google | [Link](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py) | June 2020 |
| GRU | A type of recurrent neural network that is simpler than LSTM and also captures long-term dependencies. | Google | [Link](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py) | June 2020 |
| Seq2Seq | A model used for sequence-to-sequence tasks, such as translation. | Google | [Link](https://github.com/google/seq2seq) | December 2016 |
| Transformer | A model architecture that uses self-attention mechanisms for sequence processing. | Google | [Link](https://github.com/tensorflow/models/tree/master/official/transformer) | June 2017 |
| BART | A model that combines bidirectional and autoregressive transformers for sequence generation. | Facebook AI Research | [Link](https://github.com/pytorch/fairseq/tree/master/examples/bart) | March 2020 |
| T5 | A text-to-text transformer that can handle various NLP tasks by converting them into a text generation format. | Google | [Link](https://github.com/google-research/text-to-text-transfer-transformer) | July 2021 |
| XLNet | A generalized autoregressive pretraining model that captures bidirectional context. | Google | [Link](https://github.com/zihangdai/xlnet) | June 2019 |
| RoBERTa | An optimized version of BERT that improves performance on various NLP tasks. | Facebook AI Research | [Link](https://github.com/pytorch/fairseq/tree/master/examples/roberta) | July 2021 |
| DistilBERT | A distilled version of BERT that is smaller and faster while retaining most of its performance. | Hugging Face | [Link](https://github.com/huggingface/transformers/tree/master/examples/distillation) | October 2020 |
| ALBERT | A lite version of BERT that reduces model size with parameter sharing and factorized embeddings. | Google | [Link](https://github.com/google-research/ALBERT) | September 2020 |
| XLM | A cross-lingual language model that learns representations for multiple languages. | Facebook AI Research | [Link](https://github.com/facebookresearch/XLM) |
| XLM-RoBERTa | A multilingual version of RoBERTa that performs well on various cross-lingual tasks. | Facebook AI Research | [Link](https://github.com/pytorch/fairseq/tree/master/examples/xlmr) | March 2021 |
| FlauBERT | A French language model that is pre-trained on a large corpus of French text. | GETALP | [Link](https://github.com/getalp/Flaubert) | December 2020 |
| mBART | A multilingual sequence-to-sequence model that can perform various NLP tasks across languages. | Facebook AI Research | [Link](https://github.com/pytorch/fairseq/tree/master/examples/mbart) | March 2021 |
| ELECTRA | A model that trains discriminators to distinguish real from fake tokens, improving efficiency. | Google | [Link](https://github.com/google-research/electra) | March 2021 |
| DeBERTa | A model that enhances BERT with disentangled attention and an improved mask decoder. | Microsoft | [Link](https://github.com/microsoft/DeBERTa) | February 2021 |
| REALM | A model that integrates retrieval into language modeling for enhanced understanding. | Google | [Link](https://github.com/google-research/realm) | October 2020 |
| CTRL | A conditional transformer language model that can generate text based on control codes. | Salesforce | [Link](https://github.com/salesforce/ctrl) | September 2019 |
| GPT-2 | A predecessor to GPT-3, known for generating coherent and contextually relevant text. | OpenAI | [Link](https://github.com/openai/gpt-2) | November 2019 |
| Megatron-LM | A large language model designed for efficient training on multiple GPUs. | Nvidia | [Link](https://github.com/NVIDIA/Megatron-LM) | March 2021 |
| DALL-E | A model that generates images from textual descriptions, showcasing creativity and understanding. | OpenAI | [Link](https://openai.com/blog/dall-e/) | January 2021 |
| CLIP | A model that connects images and text, allowing for zero-shot classification of images based on text prompts. | OpenAI | [Link](https://openai.com/research/clip/) | January 2021 |
| StyleGAN | A generative adversarial network that creates high-quality images with controllable styles. | Nvidia | [Link](https://github.com/NVlabs/stylegan) | February 2021 |
| BigGAN | A large-scale GAN that generates high-fidelity images with improved diversity. | Google | [Link](https://github.com/ajbrock/BigGAN-PyTorch) | January 2021 |
| CycleGAN | A model that translates images from one domain to another without paired examples. | UC Berkeley | [Link](https://github.com/junyanz/CycleGAN) | November 2020 |
| StarGAN | A unified model for multi-domain image-to-image translation. | Yunjey Choi et al. | [Link](https://github.com/yunjey/stargan) | September 2018 |
| pix2pix | A conditional GAN for image-to-image translation tasks. | Phillip Isola et al. | [Link](https://github.com/phillipi/pix2pix) | January 2017 |
| DeepSpeech | An automatic speech recognition system based on deep learning. | Mozilla | [Link](https://github.com/mozilla/DeepSpeech) | March 2021 |
| Wav2Vec | A self-supervised model for learning representations from raw audio data. | Facebook AI Research | [Link](https://github.com/pytorch/fairseq/tree/master/examples/wav2vec) | June 2021 |
| HuBERT | A self-supervised learning model for speech representation learning. | Facebook AI Research | [Link](https://github.com/facebookresearch/hubert) | April 2021 |
| Whisper | A model for automatic speech recognition and transcription. | OpenAI | [Link](https://openai.com/research/whisper) | December 2022 |
