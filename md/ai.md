# Artificial Intelligence (AI)
Notes along the AI journey

## Prompt Engineering Roadmap
* [Prompt Engineering Roadmap](https://roadmap.sh/prompt-engineering)

## Prompt Engineering Guides
* [DAIR.AI](https://www.promptingguide.ai/)
* [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)
* [Anthropic](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
* [Learn Prompting](https://learnprompting.org/docs/introduction)
* [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)
* [GitHub Copilot](https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot)
* [Brex](https://github.com/brexhq/prompt-engineering)
* [Cohere Docs](https://docs.cohere.com/docs/crafting-effective-prompts)
* [Claude Prompt Engineering Guide](https://cheatsheet.md/claude/claude-prompt-engineering)
* [How to get Codex to produce the code you want! _(Microsoft)_](https://microsoft.github.io/prompt-engineering/)

## Best Practices
* [Best practices for prompt engineering with the OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)

## Cheatsheets
* [The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 1 _(Maximilian Vogel)_](https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-mxkcf/)
* [The Perfect Prompt: A Prompt Engineering Cheat Sheet - Part 2 _(Maximilian Vogel)_](https://www.linkedin.com/pulse/perfect-prompt-engineering-cheat-sheet-snippets-part-vogel-ukysf)
* [Midjourney Commands Cheatsheet _(aituts.com)_](https://aituts.com/midjourney-cheatsheet/)
* [ChatGPT Prompt Book _(Dr. Alan D. Thompson)_](https://lifearchitect.ai/chatgpt-prompt-book/)
* [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts)
* [ChatGPT Prompts for Data Science!](https://github.com/travistangvh/ChatGPT-Data-Science-Prompts)
* [How to Write the Best ChatGPT Prompts (Cheat Sheet for 2024)](https://www.superside.com/blog/chatgpt-prompts)
* [Stable Diffusion Prompt Book](https://openart.ai/promptbook)
* [DALL-E 2 Prompt Book](https://dallery.gallery/the-dalle-2-prompt-book/)
* [7 Best ChatGPT Cheat Sheets in 2024](https://usefulai.com/cheat-sheets/chatgpt)
* [AIFire Cheatsheets](https://www.aifire.co/p/top-ai-cheatsheets-2024)

## Prompt Engineering Patterns
* [Awesome Prompting](https://github.com/corralm/awesome-prompting)

## Online Courses
* [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
* [Pair Programming with a Large Language Model](https://www.deeplearning.ai/short-courses/pair-programming-llm/)
* [Prompt Engineering with Llama 2 & 3](https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/)
* [Generative AI for Beginners _(Microsoft)_](https://github.com/microsoft/generative-ai-for-beginners)
* [Learning Prompt _(Jimmy Wong)_](https://learningprompt.wiki/)
* [Awesome Prompt Engineering _(Natasha Newbold)_](https://natnew.github.io/Awesome-Prompt-Engineering/)

## Compilations
* [Awesome GPT Prompt Engineering](https://github.com/snwfdhmp/awesome-gpt-prompt-engineering)
* [Awesome Prompt Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)
* [Awesome Prompts](https://github.com/ai-boost/awesome-prompts)
* [AIFire AI Learning Resources](https://www.aifire.co/c/ai-learning-resources)

## Tools
* [ChatGPT Prompt Generator](https://huggingface.co/spaces/merve/ChatGPT-prompt-generator)
* [Training Dataset used for the ChatGPT Prompt Generator](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts/viewer/default/train)

## Communities

| Name | Description |
|------|-------------|
| [Hugging Face](https://huggingface.co) | One of the largest AI model and dataset repositories. Offers pre-trained models for various tasks like text generation, translation, image classification. Allows community contributions. Provides hosting solutions like Inference Endpoints. |
| [Kaggle](https://www.kaggle.com)       | World's largest data science community with tools and resources for machine learning and data science projects. Users can participate in coding competitions, access datasets, notebooks, and pre-trained models. Provides a platform for hosting and sharing models, datasets, and projects. |

## Frontier Models

<!-- list 50 frontier ai models. display the results in a tabular format with columns for model name as a hyperlink to website, capabilities, release date. -->
| Model Name | Capabilities | Release Date |
|------------|--------------|--------------|
| [GPT-4](https://openai.com/research/gpt-4) | Language, Vision | April 2023 |
| [Gemini 1.5](https://ai.googleblog.com/2024/02/gemini-15.html) | Language, Vision | February 2024 |
| [Mistral Large](https://mistral.ai/models/mistral-large) | Language | February 2024 |
| [Claude 3](https://www.anthropic.com/claude) | Language, Vision | March 2024 |
| [Inflection-2](https://inflection.ai) | Language | November 2023 |
| [Grok 1](https://x.ai/grok) | Language | November 2023 |
| [PaLM 2](https://ai.googleblog.com/2023/04/palm-2.html) | Language | April 2023 |
| [DALL-E 2](https://openai.com/dall-e-2) | Image Generation | April 2022 |
| [Stable Diffusion 2.0](https://stability.ai/blog/stable-diffusion-2-0) | Image Generation | November 2022 |
| [LLaMA 2](https://ai.facebook.com/blog/large-language-models-llama-2) | Language | July 2023 |
| [Flamingo](https://deepmind.com/research/publications/flamingo) | Language, Vision | December 2022 |
| [Grok 2](https://x.ai/grok-2) | Language | March 2024 |
| [ChatGPT](https://openai.com/chatgpt) | Language | November 2022 |
| [Bard](https://bard.google.com) | Language | March 2023 |
| [OpenAI Codex](https://openai.com/research/codex) | Code Generation | August 2021 |
| [DeepMind's Gato](https://deepmind.com/research/publications/gato) | Multimodal | May 2022 |
| [Anthropic's Claude](https://www.anthropic.com/claude) | Language, Vision | March 2023 |
| [Turing-NLG](https://www.microsoft.com/en-us/research/project/turing-natural-language-generation) | Language | February 2021 |
| [EleutherAI GPT-NeoX](https://www.eleuther.ai/projects/gpt-neox) | Language | January 2022 |
| [Cohere Command R](https://cohere.ai) | Language | September 2023 |
| [Meta's OPT](https://ai.facebook.com/tools/opt) | Language | May 2022 |
| [Google's PaLM](https://ai.google.com/palm) | Language | April 2022 |
| [Mistral 7B](https://mistral.ai/models/mistral-7b) | Language | September 2023 |
| [ChatGPT-4.5](https://openai.com/research/chatgpt-4-5) | Language | March 2024 |
| [OpenAI's Whisper](https://openai.com/research/whisper) | Speech Recognition | September 2022 |
| [Jasper AI](https://www.jasper.ai) | Language | January 2021 |
| [Copy.ai](https://www.copy.ai) | Language | December 2020 |
| [Writer](https://writer.com) | Language | 2021 |
| [Runway's Gen-2](https://runwayml.com/gen-2) | Video Generation | March 2023 |
| [Synthesia](https://www.synthesia.io) | Video Generation | 2021 |
| [DeepAI](https://deepai.org) | Image Generation | 2020 |
| [DALL-E 3](https://openai.com/dall-e-3) | Image Generation | September 2023 |
| [OpenAI's CLIP](https://openai.com/research/clip) | Image, Language | January 2021 |
| [DeepMind's AlphaFold](https://deepmind.com/research/case-studies/alphafold) | Protein Folding | July 2021 |
| [Google's BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) | Language | November 2018 |
| [XLNet](https://arxiv.org/abs/1906.08237) | Language | June 2019 |
| [T5](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) | Language | February 2020 |
| [Reformer](https://arxiv.org/abs/2001.04451) | Language | January 2020 |
| [BigGAN](https://arxiv.org/abs/1809.11096) | Image Generation | September 2018 |
| [StyleGAN2](https://arxiv.org/abs/1912.04958) | Image Generation | December 2019 |
| [VQGAN](https://arxiv.org/abs/2010.04758) | Image Generation | October 2020 |
| [CLIPDraw](https://arxiv.org/abs/2106.14843) | Image Generation | June 2021 |
| [Swin Transformer](https://arxiv.org/abs/2103.14030) | Vision | March 2021 |
| [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929) | Vision | October 2020 |
| [YOLOv5](https://github.com/ultralytics/yolov5) | Object Detection | June 2020 |
| [Detectron2](https://github.com/facebookresearch/detectron2) | Object Detection | August 2019 |
| [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) | Pose Estimation | 2018 |
| [AlphaZero](https://deepmind.com/research/case-studies/alphazero) | Game Playing | December 2017 |
| [Codex](https://openai.com/research/codex) | Code Generation | August 2021 |
| [FLAN-T5](https://ai.google.com/research/flan) | Language | September 2022 |
| [Grok 3](https://x.ai/grok-3) | Language | April 2024 |
| [Anthropic's Claude 2](https://www.anthropic.com/claude) | Language, Vision | July 2023 |

## Pre-trained Models

| Model | Full Name | Description | Company | Date         |
|-------|-----------|-------------|---------|--------------|
| [BERT](https://github.com/google-research/bert) | Bidirectional Encoder Representations from Transformers | Designed for understanding the context of words in search queries. | Google | March 2021 |
| [GPT-3](https://openai.com/blog/gpt-3/) | Generative Pre-trained Transformer 3 | A state-of-the-art language model capable of generating human-like text based on prompts. | OpenAI | June 2020 |
| [ResNet](https://github.com/KaimingHe/deep-residual-networks) | Residual Network | A deep residual learning framework that helps in training very deep neural networks. | Microsoft | January 2020 |
| [VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) | Visual Geometry Group | A convolutional neural network architecture known for its simplicity and depth, used primarily for image classification. | University of Oxford | September 2015 |
| [YOLO](https://pjreddie.com/darknet/yolo/) | You Only Look Once | A real-time object detection system that detects objects in images and videos. | Joseph Redmon | April 2020 |
| [SSD](https://github.com/weiliu89/caffe/tree/ssd) | Single Shot MultiBox Detector | A single-shot detector that detects objects in images using a single deep neural network. | Wei Liu | March 2016 |
| [Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn) | Faster Region-based Convolutional Neural Network | An object detection model that combines region proposal networks with fast R-CNN. | Microsoft | April 2017 |
| [Mask R-CNN](https://github.com/matterport/Mask_RCNN) | Mask Region-based Convolutional Neural Network | An extension of Faster R-CNN that adds a branch for predicting segmentation masks on each Region of Interest (RoI). | Facebook AI Research | November 2018 |
| [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) | U-Net Convolutional Network | A convolutional network architecture for biomedical image segmentation. | University of Freiburg | January 2018 |
| [SegNet](https://github.com/alexgkendall/SegNet-Tutorial) | Segmentation Network | A deep convolutional encoder-decoder architecture for semantic segmentation. | University of Cambridge | August 2017 |
| [PSPNet](https://github.com/hszhao/PSPNet) | Pyramid Scene Parsing Network | A semantic segmentation model that captures global context information through a pyramid pooling module. | University of Science and Technology of China | March 2018 |
| [DeepLabV3](https://github.com/tensorflow/models/tree/master/research/deeplab) | DeepLab Version 3 | A semantic segmentation model that uses atrous convolution to capture multi-scale context. | Google | October 2019 |
| [DeepLabV3+](https://github.com/tensorflow/models/tree/master/research/deeplab) | DeepLab Version 3 Plus | An improved version of DeepLabV3 that includes an encoder-decoder structure for better segmentation. | Google | October 2019 |
| [EfficientNet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet) | Efficient Neural Network | A family of convolutional neural networks that scale efficiently with model size and input resolution. | Google | September 2020 |
| [MobileNet](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v2.md) | Mobile Neural Network | A lightweight model designed for mobile and edge devices, optimized for speed and efficiency. | Google | June 2019 |
| [ShuffleNet](https://github.com/megvii-model/ShuffleNet) | Shuffle Neural Network | A lightweight convolutional neural network architecture designed for mobile devices. | Megvii Technology | January 2018 |
| [SqueezeNet](https://github.com/forresti/SqueezeNet) | Squeeze Neural Network | A small, efficient convolutional neural network that achieves AlexNet-level accuracy with fewer parameters. | DeepScale | March 2020 |
| [GAN](https://github.com/goodfeli/adversarial) | Generative Adversarial Network | A framework for training generative models using adversarial training. | Ian Goodfellow et al. | November 2014 |
| [VAE](https://github.com/dpkingma/vae) | Variational Autoencoder | A generative model that learns to encode data into a latent space and decode it back. | Diederik P Kingma et al. | December 2013 |
| [DCGAN](https://github.com/pytorch/examples/tree/master/dcgan) | Deep Convolutional GAN | A type of GAN that uses deep convolutional networks for generating images. | Facebook AI Research | March 2016 |
| [WGAN](https://github.com/martinarjovsky/WassersteinGAN) | Wasserstein GAN | A variant of GAN that uses Wasserstein distance for training stability. | Martin Arjovsky et al. | June 2017 |
| [LSTM](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py) | Long Short-Term Memory | A type of recurrent neural network that can learn long-term dependencies. | Google | June 2020 |
| [GRU](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py) | Gated Recurrent Unit | A type of recurrent neural network that is simpler than LSTM and also captures long-term dependencies. | Google | June 2020 |
| [Seq2Seq](https://github.com/google/seq2seq) | Sequence-to-Sequence | A model used for sequence-to-sequence tasks, such as translation. | Google | December 2016 |
| [Transformer](https://github.com/tensorflow/models/tree/master/official/transformer) | Transformer Model | A model architecture that uses self-attention mechanisms for sequence processing. | Google | June 2017 |
| [BART](https://github.com/pytorch/fairseq/tree/master/examples/bart) | Bidirectional and Auto-Regressive Transformers | A model that combines bidirectional and autoregressive transformers for sequence generation. | Facebook AI Research | March 2020 |
| [T5](https://github.com/google-research/text-to-text-transfer-transformer) | Text-to-Text Transfer Transformer | A text-to-text transformer that can handle various NLP tasks by converting them into a text generation format. | Google | July 2021 |
| [XLNet](https://github.com/zihangdai/xlnet) | Generalized Autoregressive Pretraining | A generalized autoregressive pretraining model that captures bidirectional context. | Google | June 2019 |
| [RoBERTa](https://github.com/pytorch/fairseq/tree/master/examples/roberta) | A Robustly Optimized BERT Pretraining Approach | An optimized version of BERT that improves performance on various NLP tasks. | Facebook AI Research | July 2021 |
| [DistilBERT](https://github.com/huggingface/transformers/tree/master/examples/distillation) | Distilled BERT | A distilled version of BERT that is smaller and faster while retaining most of its performance. | Hugging Face | October 2020 |
| [ALBERT](https://github.com/google-research/ALBERT) | A Lite BERT | A lite version of BERT that reduces model size with parameter sharing and factorized embeddings. | Google | September 2020 |
| [XLM](https://github.com/facebookresearch/XLM) | Cross-lingual Language Model | A cross-lingual language model that learns representations for multiple languages. | Facebook AI Research | July 2021 |
| [XLM-RoBERTa](https://github.com/pytorch/fairseq/tree/master/examples/xlmr) | Cross-lingual RoBERTa | A multilingual version of RoBERTa that performs well on various cross-lingual tasks. | Facebook AI Research | March 2021 |
| [FlauBERT](https://github.com/getalp/Flaubert) | French Language Model | A French language model that is pre-trained on a large corpus of French text. | GETALP | December 2020 |
| [mBART](https://github.com/pytorch/fairseq/tree/master/examples/mbart) | Multilingual BART | A multilingual sequence-to-sequence model that can perform various NLP tasks across languages. | Facebook AI Research | March 2021 |
| [ELECTRA](https://github.com/google-research/electra) | Efficiently Learning an Encoder that Classifies Token Replacements Accurately | A model that trains discriminators to distinguish real from fake tokens, improving efficiency. | Google | March 2021 |
| [DeBERTa](https://github.com/microsoft/DeBERTa) | Decoding-enhanced BERT with Disentangled Attention | A model that enhances BERT with disentangled attention and an improved mask decoder. | Microsoft | February 2021 |
| [REALM](https://github.com/google-research/realm) | Retrieval-Augmented Language Model | A model that integrates retrieval into language modeling for enhanced understanding. | Google | October 2020 |
| [CTRL](https://github.com/salesforce/ctrl) | Conditional Transformer Language Model | A conditional transformer language model that can generate text based on control codes. | Salesforce | September 2019 |
| [GPT-2](https://github.com/openai/gpt-2) | Generative Pre-trained Transformer 2 | A predecessor to GPT-3, known for generating coherent and contextually relevant text. | OpenAI | November 2019 |
| [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) | Megatron Language Model | A large language model designed for efficient training on multiple GPUs. | Nvidia | March 2021 |
| [DALL-E](https://openai.com/blog/dall-e/) | DALL-E: Creating Images from Text | A model that generates images from textual descriptions, showcasing creativity and understanding. | OpenAI | January 2021 |
| [CLIP](https://openai.com/research/clip/) | Contrastive Language-Image Pre-training | A model that connects images and text, allowing for zero-shot classification of images based on text prompts. | OpenAI | January 2021 |
| [StyleGAN](https://github.com/NVlabs/stylegan) | Style Generative Adversarial Network | A generative adversarial network that creates high-quality images with controllable styles. | Nvidia | February 2021 |
| [BigGAN](https://github.com/ajbrock/BigGAN-PyTorch) | Large Scale GAN | A large-scale GAN that generates high-fidelity images with improved diversity. | Google | January 2021 |
| [CycleGAN](https://github.com/junyanz/CycleGAN) | Cycle-Consistent Adversarial Networks | A model that translates images from one domain to another without paired examples. | UC Berkeley | November 2020 |
| [StarGAN](https://github.com/yunjey/stargan) | Star Generative Adversarial Network | A unified model for multi-domain image-to-image translation. | Yunjey Choi et al. | September 2018 |
| [pix2pix](https://github.com/phillipi/pix2pix) | Image-to-Image Translation with Conditional Adversarial Networks | A conditional GAN for image-to-image translation tasks. | Phillip Isola et al. | January 2017 |
| [DeepSpeech](https://github.com/mozilla/DeepSpeech) | Deep Speech Recognition | An automatic speech recognition system based on deep learning. | Mozilla | March 2021 |
| [Wav2Vec](https://github.com/pytorch/fairseq/tree/master/examples/wav2vec) | Wav2Vec: Unsupervised Pre-training for Speech Recognition | A self-supervised model for learning representations from raw audio data. | Facebook AI Research | June 2021 |
| [HuBERT](https://github.com/facebookresearch/hubert) | Hidden Unit BERT | A self-supervised learning model for speech representation learning. | Facebook AI Research | April 2021 |
| [Whisper](https://openai.com/research/whisper) | Whisper: Automatic Speech Recognition | A model for automatic speech recognition and transcription. | OpenAI | December 2022 |
